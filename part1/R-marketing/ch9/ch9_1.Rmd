---
title: "R4maket_ch9"
author: "ksg"
date: "2015년 9월 18일"
output: 
  html_document: 
    keep_md: yes
---

#9. Additional Linear Modeling Topics

  - 선형회기에는 다양한 방법이 있다. 이번장에서는 추가적인 선형회기를 알아본다
  - 공산성의 문제가 생길경우 (독립변인간 높은상관을 보임) 데이터를 교정한다
  - 예, 아니오로 피팅되는 모델 혹은 binary한 결과값이 나올때(물건구매) 로지스틱회기모델 사용한다
  - 샘플뿐 아니라 전체 개인의 선호나 반응을 찾는 모델에서 우리는 소비자 개인을 이해하고 행동의 다양성과 사람들의 제품에 대한 흥미를 알고자 한다. hierarchical linear models (HLM)을 소비자의 선호평점과 결합하여 알아보자.
  - 개인의 선호에 대한 hierarchical linear models은 베이지안 방법론을 측정된다.
  - hierarchical Bayesian (HB) methods, and we apply HB for ratings-based conjoint analysis.

##9.1 Handling Highly Correlated Variables

###9.1.1 An Initial Linear Model of Online Spend

  - 데이터 로딩 
```{r}
cust.df <- read.csv("http://goo.gl/PmPkaG")
summary(cust.df)
```
complete.cases(cust.df)
  - 다중회귀분석 실시(online.spend ~ 나머지변인 전부)
  - 고객ID와 온라인 구매가 0원인 사람을 제외한다.
```{r}
spend.m1 <- lm(online.spend ~ .,data=subset(cust.df[ , -1], online.spend > 0))
summary(spend.m1)
```
  - online spend와 online transactions (coefficient = 20.6) 높은회귀계수인 
  - online spend와 online visits는 그렇지 않고  반대
  - 모델은 대부분의 변수가 모두 유용하다고본다. (R2 = 0.98) 1에가까움
  - 뭔가 이상함 : 그 이유는 온라인 전환은 온라인 방문과는 독립적이기 때문이다.
  - 그럼에도 어떻게 online spending를 잘 예측했을까? (R-squared:0.98)
  - 또한 알려준다 store.trans의 standard error가 크다, 그리고 그 측정치가 불확실하다. 
  - 문제를 알아보기 위해서 gpairs함수로 시각화를 해본다.
  - 편포와 높은상관을보이는 변인쌍 있음을 알수있다. 이를 교정해야한다.
```{r}  
library(gpairs)
gpairs(cust.df)
```

  
####Box-Cox transformation  
  - Box-Cox변환이란 데이터들이 등분산을 갖는 정규분포가 되도록 변환시키는 것
  - 데이터들이 등분산이고 정규분포라는 가정하에서 여러 이론들을 정립됨
  - Box-Cox Transformation으로 데이터를변환시키면 회귀분석, 가설검정, ANOVA 등이 적용가느 
  - 함수작성 : BoxCox.lambda(x) 람다값 찾음, BoxCox함수로 변환 scale()함수로 표준화
```{r} 
#install.packages("forecast")
autoTransform <- function(x) {
  library(forecast)
  return(scale(BoxCox(x, BoxCox.lambda(x))))
  } 
```


  - 박스콕스 변환 실시
  - NA가 없는 데이터만 고객ID를 빼고 cust.df.bc 할당
  - 온라인구매금액이 있는 사람만 cust.df.bc 할당
  - email변수 빼고 나머지만 autoTransform 적용하여 cust.df.bc에 덥어쓰기 
```{r} 
cust.df.bc <- cust.df[complete.cases(cust.df), -1] 
cust.df.bc <- subset(cust.df.bc, online.spend > 0) 
numcols <- which(colnames(cust.df.bc) != "email")  
cust.df.bc[ , numcols] <- lapply(cust.df.bc[ , numcols], autoTransform ) 
```

  - 변환된 데이터 확인
```{r}
summary(cust.df.bc) 
gpairs(cust.df.bc)
```

  - LM모델에 피팅(online.spend ~ 나머지 전부)
  - LM모델에 피팅(online.spend ~ online.trans)
  - R2와 P값이 큰차이가 없다면 심플한 모델이 더 좋음
```{r}
spend.m2 <- lm(online.spend ~ ., data=cust.df.bc)
summary(spend.m2)
spend.m3 <- lm(online.spend ~ online.trans, data=cust.df.bc)
summary(spend.m3)
```

  - anova() 함수로 모델을 비교해봄
  - 통계적으로 두 모델의 차이는 유의미하지않음(p값 0.8)
```{r}
anova(spend.m3, spend.m2)
```
  - 이를 공선성의 문제(collinearity)라함
  - 결정계수 R2값은 높아 회귀식의 설명력은 높음
  - 그러나 한변수의 P-value값이 커서 다른변수들이 유의하지 않ㅇ
  - 이는 표준오차의 증가를 야기시킴(즉, 회귀계수가 불안정함, 샘플에 따라 쉽게 바뀜)
  
###9.1.2 Remediating Collinearity 
 
  - 공선성의 정도는 variance inflation factor(VIF-분산팽창요인)로 진단함
  - VIF는 얼마나 표준오차가 발생하는지 상관이 없는 또는 다른 변인들과 회기와 성능을 비교하는 것이다.
  - 일반적을 VIF > 5.0 이면, 공선성의 교정이 필요함을 의미한다.
  - spend.m2 모델에서 online.visits, online.trans, store.trans, store.spend 공선성이 확인된다.
```{r}
library(car)
vif(spend.m2)
```
  - <공선성 교정 3가지 방법>
  - 1) 높은 상관의 변인을 제외한다.
  - 2) 주성분의 추출을 통해 상관을 제거한다.(8장의 주성분 분석)
  - 3) 공선성에 둔감한 방법을 사용한다.(전통적인 회귀가 아닌, 랜덤포레스트-11장)
  - 기타) 현재 데이터를 믹스하여 새로운 변수를 만든다.(such as spend per transaction)
  - 1,2번의 접근을 실시해보자
  
### <공선성 교정> 
  - 높은상관의 변인제거
  - online visit은 좋은 예측지표가 됬다. 또한 email status, age도 상관이 발견됬다.
```{r}
spend.m4 <- lm(online.spend ~ . -online.trans -store.trans,data=cust.df.bc) 
summary(spend.m4)
vif(spend.m4)
```
  - 2) 주성분의 추출
  - 주성분분석에서 직교개념=>새로운 상관없는 차원 생성=>공선성없음 
  - online.visits, online.trans 두개로부터 주성분을 하나 추출(pc.online)
  - store.trans, store.spend 두개로부터 주성분을 하나 추출(pc.store)
```{r}
pc.online <- prcomp(cust.df.bc[ , c("online.visits", "online.trans")])
cust.df.bc$online <- pc.online$x[ , 1]
summary(pc.online)
pc.store <- prcomp(cust.df.bc[ , c("store.trans", "store.spend")])
cust.df.bc$store <- pc.store$x[ , 1]
summary(pc.store)
```

  - 추출한 주성분을 변수로 넣고 다시 선형회기 피팅
  - online 변수가 유의미한 변수로 나옴 
```{r}
spend.m5 <- lm(online.spend ~ email + age + credit.score 
               + distance.to.store + sat.service + sat.selection 
               + online + store, data=cust.df.bc)
summary(spend.m5)
vif(spend.m5)
```

###9.2 Linear Models for Binary Outcomes: Logistic Regression

  - 로지스틱회귀의 핵심특징은 예측변인의 지수함수의 결과물로 확률로 연결된다는 것이다.
  - 고객이 물건을 구매할 확률 또는 프로모션에 응답할 확률등과 같은 관심사에 직접적인 모델이다
  - 종속변수가 0~1 범위의 값을 갖는 모델링을 하는데에 제한된다.
  - 종속변수의 값이 0.5보다 크면 사건이 발생 0.5보다 작으면 그렇지 않음
  - plogis()함수로 로지스틱회귀 방정식 계산할수 있음

```{r}
exp(0) / (exp(0) + 1) # computing logistic by hand; could use plogis()
plogis(-Inf) # infinitely low = likelihood 0
plogis(2) # moderate probability = 88% chance of outcome
plogis(-0.2) # weak likelihood
```  

  - y발생할 상대적 가능성(odds ratio)에 로그를 취해서 얻어지는 값으로 결정되는 logit모델이라 함
  - R은 이 함수를 qloigs로 산출해준다.
  - 여기서 얻은 값을 로지스틱회귀모형의 사후확률이라하고 분석자가 선정한 값보다 크면 집단1, 작으면 집단2로 분류한다.
```{r}
log(0.88 / (1-0.88)) # moderate high likelihood
qlogis(0.88) # equivalent to hand computation
```


###9.2.2 Data for Logistic Regression of Season Passes

  - 7장의 놀이공원 데이터 예재 : 시즌티켓 구매여부가 포함된 데이터임
  - 2가지 변인에 기초함 - 사전메일 받았는지, 프로모션 혜택을 제공하였는지(무료주차권)
  - 마케터는 번들(주차권)제공시 고객의 구매를 촉진하는지 궁금하다.
  - data 로딩
```{r}
pass.df <- read.csv("http://goo.gl/J8MH6A")
pass.df$Promo <- factor(pass.df$Promo, levels=c("NoBundle", "Bundle"))
summary(pass.df)
head(pass.df)
```

  - 테이블 형태를 변형(카이스퀘어 분석 등에 용이하게끔)
```{r}
pass.tab <- c(242, 639, 38, 359, 284, 27, 449, 223, 83, 278, 49, 485)
dim(pass.tab) <- c(3,2,2)
class(pass.tab) <- "table"
dimnames(pass.tab) <- list(Channel=c("Mail", "Park", "Email"),
                           Promo=c("Bundle", "NoBundle"),
                           Pass=c("YesPass", "NoPass") )
pass.tab
```

```{r}
table(pass.df)
```

###9.2.5 Finalizing the Data
  - 테이블을 데이터프레임브로 변환할수 있음
  - vcdExtra패키지의 expand.dft()함수 사용
```{r}
#install.packages("vcdExtra")
library(vcdExtra)
pass.df <- expand.dft(pass.tab)
str(pass.df)
head(pass.df)
```
  
  
  - table() 함수로 교차표 생성 가능 구매여부/프로모션 번들
```{r}
table(pass.df$Pass, pass.df$Promo)
```


  - 회귀모형에서 번들의 긍정적인효과는 음의값을 의미한다.
  - 난해한 로직(노번들에서 부정적효과를 확인함)보다 쉽게 해석하기위해 변수 재할당
```{r}
pass.df$Promo <- factor(pass.df$Promo, levels=c("NoBundle", "Bundle"))
table(pass.df$Pass, pass.df$Promo)
```

###9.2.6 Fitting a Logistic Regression Model
  - GLM은 정상분포가 아닌 변인들을 다룰 수 있다.
  - GLM은 구매회수, 웹사이트 방문시간, yes/no와 같은 변인을 다룬다.
  - GLM의 일반적 특징은 정규분포된 예측치로 비정규분포의 결과물을 산출하는 함수
  - GLM은 링크라고 알려진 함수를 사용해 정규분포된 예측치로 비정규분포의 결과물을 산출한다.
  - GML패키지는 다양한 함수를 제공한다. family인수에 입력해야한다.  
  - 이항결과를 산출하기 위해서 family=binomial 인수를 써야함
  - 인수를 넣지 않으면 logit 함수가 적용됨
  - 우리는 "번들 프로모션이 시즌권 판매에 효과가 있는가?"이다.
```{r}
pass.m1 <- glm(Pass ~ Promo, data=pass.df, family=binomial)
summary(pass.m1)
```
  - coefficient : 0.3888  / p밸류 : 5.81e-08 (번들은 시즌권 판매에 유의한 영향을 미쳤음)
  - 0.388값을 시즌권판매 관계 계산에 이용할수 있음 성공확률*비성공확률을 plogis함수에 직접 넣음
```{r}
plogis(0.3888) / (1-plogis(0.3888))
```
  - effect of Bundle is an estimated odds ratio of 1.475
  - 이는 번들제공시 시즌권을 살 확률이 147%라는 것이다. 즉, 번들이 구매 확률을 47% 증가 시켰다는 것을 의미한다. 
  - 쉽게 이를 계산하는 방법은 exp함수에 넣는것이다.
```{r}
exp(0.3888)
exp(coef(pass.m1))
```

  - We can obtain a confidence interval for the odds ratio using exp(confint(model))
```{r}
exp(confint(pass.m1))
```

###9.2.7 Reconsidering the Model

  - 추가적인 탐색을 통해 흥미로운 사실을 발견할 수있다.(채널변수)
  - 놀이공원(park)에서 직접 구매한 사람이 제일 많다.
  - 테이블을 시각화하는 좋은 방법은 모자이크플랏이다.
  - doubledecker 플랏(기존 모자이크플랏보다 좋음)으로 data확인
```{r}
table(pass.df$Pass, pass.df$Channel)
library(vcd)
doubledecker(table(pass.df))
```

  - 채널을 넣어서 다시 GLM돌려보자
  - 프로모션은 강하게 부정적인 기여를 한다.
```{r}
pass.m2 <- glm(Pass ~ Promo + Channel, data=pass.df, family=binomial)
summary(pass.m2)
```

  - compute the odds ratios and confidence intervals
  - 번들프로모션은 32–53 % 구매확률을 낮추는것과 관련된다.
  - 공원에서 판매는 30~56으로 더 높아졌다.
```{r}
exp(coef(pass.m2))
exp(confint(pass.m2))
```
  - 이를 적절한 모델이라고 할수 있는가?
  - 번들플모션은 채널에 의해 차별적으로 영향을 미친다.
  - 번들-이메일간에 극적인 차이를 보이므로 상호작용효과를 보자.
```{r}
pass.m3 <- glm(Pass ~ Promo + Channel + Promo:Channel,
               data=pass.df, family=binomial)
summary(pass.m3)
```
  - 채널과 프로모션의 상호작용은 통계적으로 유의미함
  - mail, in-park*프로모션 상호작용은 강하게 부적인 효과
  - odds ratios, promotion is only 2–11 % as effective through the mail and in-park channels as it is in email:

```{r}
exp(confint(pass.m3))
```


